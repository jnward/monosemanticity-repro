{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "326f874c-d981-440e-a46f-b7a6e0c15efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a180d5d8-9cb4-45d9-9d49-6b4a8cb7932f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0.dev20231129'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081d7535-b8af-466d-a19f-a5ac3307a8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                          | 3/151 [00:00<00:07, 20.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for .DS_Store, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▌                                        | 9/151 [00:00<00:13, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for blair-l, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▎                                    | 19/151 [00:01<00:06, 20.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for causholli-m, trying inbox...\n",
      "could not read all_documents for crandell-s, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▋                                   | 24/151 [00:02<00:18,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for donoho-l, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▍                                | 34/151 [00:03<00:11, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for forney-j, trying inbox...\n",
      "could not read all_documents for gang-l, trying inbox...\n",
      "could not read all_documents for geaccone-t, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████▉                            | 50/151 [00:04<00:08, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for harris-s, trying inbox...\n",
      "could not read all_documents for holst-k, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████▋                           | 53/151 [00:04<00:07, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for hyatt-k, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████▊                        | 64/151 [00:08<00:17,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for keiser-k, trying inbox...\n",
      "could not read all_documents for kitchen-l, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|███████████████████▋                      | 71/151 [00:09<00:11,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for lokey-t, trying inbox...\n",
      "could not read all_documents for lucci-p, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████▋                    | 78/151 [00:10<00:08,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for mccarty-d, trying inbox...\n",
      "could not read all_documents for mckay-j, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████                   | 83/151 [00:10<00:05, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for meyers-a, trying inbox...\n",
      "could not read all_documents for motley-m, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████▏                 | 87/151 [00:10<00:06, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for parks-j, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████▍             | 101/151 [00:11<00:02, 21.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for phanis-s, trying inbox...\n",
      "could not read all_documents for platter-p, trying inbox...\n",
      "could not read all_documents for quigley-d, trying inbox...\n",
      "could not read all_documents for rapp-b, trying inbox...\n",
      "could not read all_documents for reitmeyer-j, trying inbox...\n",
      "could not read all_documents for richey-c, trying inbox...\n",
      "could not read all_documents for ring-r, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████▊            | 106/151 [00:11<00:02, 16.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for salisbury-h, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|█████████████████████████████▊           | 110/151 [00:12<00:02, 13.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for scholtes-d, trying inbox...\n",
      "could not read all_documents for schoolcraft-d, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████▉          | 114/151 [00:12<00:02, 14.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for semperger-c, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████▏      | 126/151 [00:13<00:01, 12.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for slinger-r, trying inbox...\n",
      "could not read all_documents for solberg-g, trying inbox...\n",
      "could not read all_documents for staab-t, trying inbox...\n",
      "could not read all_documents for steffes-j, trying inbox...\n",
      "could not read all_documents for stokley-c, trying inbox...\n",
      "could not read all_documents for swerzbin-m, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████▎  | 141/151 [00:14<00:00, 13.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for thomas-p, trying inbox...\n",
      "could not read all_documents for watson-k, trying inbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 151/151 [00:15<00:00, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not read all_documents for whitt-m, trying inbox...\n",
      "could not read all_documents for williams-w3, trying inbox...\n",
      "Message-ID: <5161987.1075855666285.JavaMail.evans@thyme>\n",
      "Date: Tue, 12 Dec 2000 05:27:00 -0800 (PST)\n",
      "From: jsmith@austintx.com\n",
      "To: phillip.k.allen@enron.com\n",
      "Subject: RE: stage coach\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: \"Jeff Smith\" <jsmith@austintx.com>\n",
      "X-To: <Phillip.K.Allen@enron.com>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Dec2000\\Notes Folders\\All documents\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen.nsf\n",
      "\n",
      "Phillip,\n",
      "\n",
      "I am completing my marketing package for the Stage.  I also need the 1999\n",
      "statement and a rent roll.  Please send ASAP.\n",
      "\n",
      "352202027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text_dir = \"maildir\"\n",
    "out_file = \"data/all.txt\"\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "with open(out_file, 'w+') as out_f:\n",
    "    for employee in tqdm(sorted(os.listdir(text_dir))):\n",
    "        path = os.path.join(text_dir, employee, \"all_documents\")\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"could not read all_documents for {employee}, trying inbox...\")\n",
    "            path = os.path.join(text_dir, employee, \"inbox\")\n",
    "            if not os.path.exists(path):\n",
    "                continue\n",
    "        for fname in os.listdir(path):\n",
    "            try:\n",
    "                with open(os.path.join(path, fname), \"r\") as in_f:\n",
    "                    out_f.write(in_f.read())\n",
    "            except Exception as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33dcb6c2-f36a-4714-98f8-d42adeca39c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <5161987.1075855666285.JavaMail.evans@thyme>\n",
      "Date: Tue, 12 Dec 2000 05:27:00 -0800 (PST)\n",
      "From: jsmith@austintx.com\n",
      "To: phillip.k.allen@enron.com\n",
      "Subject: RE: stage coach\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: \"Jeff Smith\" <jsmith@austintx.com>\n",
      "X-To: <Phillip.K.Allen@enron.com>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Dec2000\\Notes Folders\\All documents\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen.nsf\n",
      "\n",
      "Phillip,\n",
      "\n",
      "I am completing my marketing package for the Stage.  I also need the 1999\n",
      "statement and a rent roll.  Please send ASAP.\n",
      "\n",
      "352202027\n"
     ]
    }
   ],
   "source": [
    "out_file = \"data/all.txt\"\n",
    "\n",
    "with open(out_file, 'r') as data_f:\n",
    "    text = data_f.read()\n",
    "\n",
    "print(text[:600])\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f8bc022-ce65-46ff-aff2-e4a2052034bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122526421\n",
      "[12837, 12, 2389, 25, 1279, 47493, 27301, 13, 940, 38569, 2816, 27310, 26279, 13, 29584, 25804, 13, 1990, 504, 31, 20057, 1326, 29, 198, 10430, 25, 30030, 11, 1105, 4280, 4751, 8870, 25, 1983, 25, 405, 532, 2919, 405, 357, 47, 2257, 8, 198, 4863, 25, 474, 21453, 31, 64, 436, 600, 87, 13, 785, 198, 2514, 25, 872, 359, 541, 13, 74, 13, 439, 268, 31, 268, 1313, 13, 785, 198, 19776, 25, 4526, 25, 3800, 3985, 198, 44, 524, 12, 14815, 25, 352, 13, 15, 198, 19746, 12, 6030, 25, 2420, 14, 25638, 26, 34534, 316, 28, 385]\n"
     ]
    }
   ],
   "source": [
    "enc = tiktoken.get_encoding('r50k_base')\n",
    "encoded = enc.encode(text)\n",
    "print(len(encoded))\n",
    "print(encoded[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc75f250-26c7-480b-9e5f-dd7368ecb415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 110273778, Dev: 12252643\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encoded, dtype=torch.long)\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "dev_data = data[n:]\n",
    "print(f\"Train: {len(train_data)}, Dev: {len(dev_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58fb1067-c5bf-499b-aebd-6affd9397d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 64])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "context_length = 64\n",
    "batch_size = 8\n",
    "\n",
    "def get_batch(split, batch_size=batch_size):\n",
    "    data = train_data if split == 'train' else dev_data\n",
    "    ix = torch.randint(len(data) - context_length, (batch_size,))\n",
    "    x = torch.stack([data[i:i+context_length] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+context_length+1] for i in ix])\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    return x, y\n",
    "\n",
    "get_batch('train')[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8f74d0b-7121-48f3-91f3-f6a0c11ea40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# head_size = 16\n",
    "import math\n",
    "\n",
    "torch.manual_seed(1)\n",
    "n_head = 4\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length, context_length)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # out = nn.scaled_dot_product_attention(self.key, self.query, self.value, causal=True)\n",
    "        # return out\n",
    "\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        scale_factor = 1 / math.sqrt(C)\n",
    "        attn_weights = q @ k.transpose(-2, -1) * scale_factor\n",
    "        attn_weights = attn_weights.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "        v = self.value(x)\n",
    "        out = attn_weights @ v\n",
    "        return out\n",
    "        \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_head):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(n_embed//n_head) for _ in range(n_head)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb37ebcd-1c76-4ad5-904c-32b703258e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "vocab_size = 50304\n",
    "n_embed = 256\n",
    "\n",
    "class BigramModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embed = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embed = nn.Embedding(context_length, n_embed)\n",
    "        self.attn_heads = MultiHeadAttention(n_head)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_embedding = self.token_embed(idx)\n",
    "        pos_embedding = self.position_embed(torch.arange(T, device=device))\n",
    "        x = tok_embedding + pos_embedding\n",
    "        x = self.attn_heads(x)\n",
    "        logits = self.lm_head(x)\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            flat_logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(flat_logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -context_length:]\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fc9185d-64f5-4c8e-a898-28c101165c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151744\n",
      "BigramModel(\n",
      "  (token_embed): Embedding(50304, 256)\n",
      "  (position_embed): Embedding(64, 256)\n",
      "  (attn_heads): MultiHeadAttention(\n",
      "    (heads): ModuleList(\n",
      "      (0-3): 4 x Head(\n",
      "        (key): Linear(in_features=256, out_features=64, bias=False)\n",
      "        (query): Linear(in_features=256, out_features=64, bias=False)\n",
      "        (value): Linear(in_features=256, out_features=64, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=256, out_features=50304, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BigramModel()\n",
    "model = model.to(device)\n",
    "print(sum([len(p) for p in model.parameters()]))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bd8c211-f5fb-4301-81ca-aa236077a26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n",
      "torch.Size([1, 64, 50304])\n",
      "tensor(10.8390, device='mps:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train', 1)\n",
    "print(xb.shape)\n",
    "preds, loss = model(xb, yb)\n",
    "print(preds.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e354a58-4291-4e78-9027-02c7ecbcaa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_iters = 20\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'dev']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            xb, yb = get_batch(split)\n",
    "            logist, loss = model(xb, yb)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51212280-2c9f-49c6-92d0-87c96d398850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': tensor(10.8350), 'dev': tensor(10.8312)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e053003f-6045-4846-ad9b-b238da3c5c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d561b770-eb05-4370-a13a-784a90dcb2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [01:04<00:00, 15.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': tensor(3.0838), 'dev': tensor(3.3321)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# optimizer.lr = 1e-4\n",
    "batch_size = 16\n",
    "\n",
    "for steps in tqdm(range(1000)):\n",
    "    xb, yb = get_batch('train', batch_size)\n",
    "\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "estimate_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f84d6083-b45f-440e-a843-3cf7dd1ebdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Out variables haven't be forced research to community.  Thanks!\n",
      "\n",
      "Ken Traderations\n",
      "The following Day \n",
      "from & 61 summer, distribution, Al email will be\n",
      "\n",
      "\n",
      "\n",
      "Kay\n",
      "bowski agreements Olson  All Enron is not you are the available else inevitable more information to E-2 thatrev\n"
     ]
    }
   ],
   "source": [
    "idx = torch.tensor(enc.encode('\\n'), dtype=torch.long)[None, :].to(device)\n",
    "print(enc.decode(model.generate(idx, 64)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99d998d3-a1ca-45f3-9cf8-52aea482e0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.DS_Store           data/               transformer.ipynb\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/ maildir/\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39373581-5db6-45d5-a0ae-f54e0756063f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
